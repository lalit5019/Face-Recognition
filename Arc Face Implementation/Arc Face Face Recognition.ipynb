{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab66108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalit\\anaconda3\\envs\\base2\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\lalit\\anaconda3\\envs\\base2\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\Users\\lalit\\anaconda3\\envs\\base2\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import face_model\n",
    "import argparse\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import insightface\n",
    "from insightface.utils import face_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f53bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 16, 8] {'32': {'SCALES': (32, 16), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '16': {'SCALES': (8, 4), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '8': {'SCALES': (2, 1), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}}\n",
      "use_landmarks True\n",
      "loading model-r100-ii/model 0\n"
     ]
    }
   ],
   "source": [
    "model = face_model.FaceModel(0,'model-r100-ii/model', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df2d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 16, 8] {'32': {'SCALES': (32, 16), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '16': {'SCALES': (8, 4), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '8': {'SCALES': (2, 1), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}}\n",
      "use_landmarks True\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "from insightface.utils import face_align\n",
    "detector = insightface.model_zoo.get_model('retinaface_mnet025_v2')\n",
    "detector.prepare(ctx_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94a7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding_and_ID = pickle.load(open('Embedding_and_ID.pkl','rb'))\n",
    "Name_and_ID = pickle.load(open('Name_and_ID.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a23ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_face(image_address):\n",
    "    t0 = time.time()\n",
    "    image = cv2.imread(image_address)\n",
    "    bbox, pts5 = detector.detect(image, threshold=0.8)\n",
    "    for i in range(len(bbox)):\n",
    "        x1, y1, x2, y2 = bbox[i,0:4]\n",
    "        x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "        nimg = face_align.norm_crop(image, pts5[i])\n",
    "        embd = model.get_feature(nimg)\n",
    "        cv2.rectangle(image, (x1,y1), (x2,y2), (0,0,255), 1)\n",
    "        max_sim = {}\n",
    "        for j in Embedding_and_ID:\n",
    "            representation = Embedding_and_ID[j]\n",
    "            similarity = np.dot(embd, representation)\n",
    "            if similarity>0.4:\n",
    "                max_sim[j] = similarity\n",
    "        if len(max_sim)!=0:\n",
    "            max_val = max(max_sim.values())\n",
    "            for key, value in max_sim.items():\n",
    "                if max_val == value:\n",
    "                    ID = key\n",
    "            person_name = Name_and_ID[ID]\n",
    "            print(max_sim[ID])\n",
    "            print(person_name)\n",
    "            cv2.putText(image, person_name, (x1, y1-2), 0, 0.5, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(image, 'unknown', (x1, y1-5), 0, 0.6, (255, 0, 0), 2)\n",
    "    cv2.imwrite('save images/'+str(22)+ '.jpg',image)\n",
    "    t4 = time.time()\n",
    "    print(t4-t0,'sec')\n",
    "    cv2.imshow('Face Recognition', image)\n",
    "    cv2.waitKey(0)    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc253bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7430223\n",
      "Narendra_Modi\n",
      "0.7892616\n",
      "Yogi_Adityanath\n",
      "0.77564627\n",
      "Amit_Shah\n",
      "0.7535145\n",
      "Manohar Parrikar\n",
      "4.114994525909424 sec\n"
     ]
    }
   ],
   "source": [
    "match_face('test images/138.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1793913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cce14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_match2(frame):\n",
    "    image = frame\n",
    "    bbox, pts5 = detector.detect(frame, threshold=0.8)\n",
    "    for i in range(len(bbox)):\n",
    "        x1, y1, x2, y2 = bbox[i,0:4]\n",
    "        x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "        nimg = face_align.norm_crop(image, pts5[i])\n",
    "        embd = model.get_feature(nimg)\n",
    "        cv2.rectangle(image, (x1,y1), (x2,y2), (0,0,255), 1)\n",
    "        max_sim = {}\n",
    "        for j in Embedding_and_ID:\n",
    "            representation = Embedding_and_ID[j]\n",
    "            similarity = np.dot(embd, representation)\n",
    "            if similarity>0.4:\n",
    "                max_sim[j] = similarity\n",
    "        if len(max_sim)!=0:\n",
    "            max_val = max(max_sim.values())\n",
    "            for key, value in max_sim.items():\n",
    "                if max_val == value:\n",
    "                    ID = key\n",
    "            person_name = Name_and_ID[ID]\n",
    "            print(max_sim[ID])\n",
    "            print(person_name)\n",
    "            cv2.putText(image, person_name, (x1, y1-2), 0, 0.5, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(image, 'unknown', (x1, y1-5), 0, 0.6, (255, 0, 0), 2)\n",
    "    if image.shape[1]> 400:\n",
    "        im2 = cv2.resize(image,(int(image.shape[1]*0.6),int(image.shape[0]*0.6)))\n",
    "    return im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ab7624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition_vid(video_address):\n",
    "    filename = video_address\n",
    "    dir_name = os.path.splitext(filename)[0]\n",
    "    parent_dir = \"video output/\"\n",
    "    directory = os.path.join(parent_dir, dir_name[12:]) \n",
    "    os.mkdir(directory)\n",
    "    seconds = 1\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    # Get the frames per second\n",
    "    fps = round(cap.get(cv2.CAP_PROP_FPS)) \n",
    "    multiplier = fps*seconds\n",
    "\n",
    "    # Get the total numer of frames in the video.\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    print(\"FC :\", frame_count)\n",
    "\n",
    "    count = -1\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret:\n",
    "            frame2 = face_match2(frame)\n",
    "            #cv2.imwrite('F:/Output/%s/Frame{:f}.jpg'.format(count),frame)\n",
    "            cv2.imwrite('video output/%s/image{:f}.jpg'.format(count)%(dir_name[12:]),frame2)\n",
    "            count += multiplier \n",
    "            cap.set(1, count)\n",
    "        else:\n",
    "            cap.release()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "623bd38e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'video output/test_video4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-091baa321ca9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mface_recognition_vid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test videos/test_video4.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-4d5ba1015b6e>\u001b[0m in \u001b[0;36mface_recognition_vid\u001b[1;34m(video_address)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mparent_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"video output/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mseconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'video output/test_video4'"
     ]
    }
   ],
   "source": [
    "face_recognition_vid('test videos/test_video4.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0b32b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_face2(frame):\n",
    "    image = frame\n",
    "    bbox, pts5 = detector.detect(frame, threshold=0.8)\n",
    "    for i in range(len(bbox)):\n",
    "        x1, y1, x2, y2 = bbox[i,0:4]\n",
    "        x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "        nimg = face_align.norm_crop(image, pts5[i])\n",
    "        embd = model.get_feature(nimg)\n",
    "        cv2.rectangle(image, (x1,y1), (x2,y2), (0,0,255), 1)\n",
    "        max_sim = {}\n",
    "        for j in Embedding_and_ID:\n",
    "            representation = Embedding_and_ID[j]\n",
    "            similarity = np.dot(embd, representation)\n",
    "            if similarity>0.43:\n",
    "                max_sim[j] = similarity\n",
    "        if len(max_sim)!=0:\n",
    "            max_val = max(max_sim.values())\n",
    "            for key, value in max_sim.items():\n",
    "                if max_val == value:\n",
    "                    ID = key\n",
    "            person_name = Name_and_ID[ID]\n",
    "            cv2.putText(image, person_name, (x1, y1-2), 0, 0.5, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(image, 'unknown', (x1, y1-5), 0, 0.6, (255, 0, 0), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46366d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('video output2/fr_webcam2.mp4',fourcc,15.0,(640,480))\n",
    "start_time = time.time()\n",
    "fps = 0\n",
    "total_frames = 0\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    total_frames = total_frames+1\n",
    "    end_time = time.time()\n",
    "    time_diff= end_time-start_time\n",
    "    if time_diff ==0:\n",
    "        fps = 0.0\n",
    "    else:\n",
    "        fps = (total_frames/time_diff)\n",
    "    fps_text =  \"FPS: {:.2f}\".format(fps)\n",
    "    img = match_face2(img)\n",
    "    cv2.putText(img, fps_text, (5,30), 0, 0.6, (100, 100, 255), 2)\n",
    "    img = cv2.resize(img,(640,480))\n",
    "    out.write(img)\n",
    "    cv2.imshow('face',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a9a69d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('test videos/test_video1.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('video output2/fr_test_video7.mp4',fourcc,11.0,(480,620))\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "fps = 0\n",
    "total_frames = 0\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if i%2 ==0:\n",
    "        img = match_face2(img)\n",
    "        total_frames = total_frames+1\n",
    "        end_time = time.time()\n",
    "        time_diff= end_time-start_time\n",
    "        if time_diff ==0:\n",
    "            fps = 0.0\n",
    "        else:\n",
    "            fps = (total_frames/time_diff)\n",
    "        fps_text =  \"FPS: {:.2f}\".format(fps)\n",
    "        cv2.putText(img, fps_text, (5,30), 0, 0.6, (100, 100, 255), 2)\n",
    "        img = cv2.resize(img,(480,620))\n",
    "        out.write(img)\n",
    "        cv2.imshow('face',img)\n",
    "    i = i+1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8684d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('test videos/test_video1.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('subscribe1.mp4',fourcc,25.0,(640,480))\n",
    "while(cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    img = cv2.resize(img,(640,480))\n",
    "    out.write(img)\n",
    "    cv2.imshow('face',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9d759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af343b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "327edac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "start_time = time.time()\n",
    "fps = 0\n",
    "total_frames = 0\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    total_frames = total_frames+1\n",
    "    end_time = time.time()\n",
    "    time_diff= end_time-start_time\n",
    "    if time_diff ==0:\n",
    "        fps = 0.0\n",
    "    else:\n",
    "        fps = (total_frames/time_diff)\n",
    "    fps_text =  \"FPS: {:.2f}\".format(fps)\n",
    "    img = match_face2(img)\n",
    "    cv2.putText(img, fps_text, (5,30), 0, 0.6, (100, 100, 255), 2)\n",
    "    img = cv2.resize(img,(640,480))\n",
    "    cv2.imshow('face',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ee67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10f3828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('test videos/test_video1.mp4')\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "fps = 0\n",
    "total_frames = 0\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if i%2 ==0:\n",
    "        img = match_face2(img)\n",
    "        total_frames = total_frames+1\n",
    "        end_time = time.time()\n",
    "        time_diff= end_time-start_time\n",
    "        if time_diff ==0:\n",
    "            fps = 0.0\n",
    "        else:\n",
    "            fps = (total_frames/time_diff)\n",
    "        fps_text =  \"FPS: {:.2f}\".format(fps)\n",
    "        cv2.putText(img, fps_text, (5,30), 0, 0.6, (100, 100, 255), 2)\n",
    "        cv2.imshow('face',img)\n",
    "    i = i+1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ff76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0077e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
